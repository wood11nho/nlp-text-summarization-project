{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!conda install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"readerbench/AlephNews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['title', 'summary', 'url', 'paragraphs'],\n",
      "        num_rows: 38683\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['title', 'summary', 'url', 'paragraphs'],\n",
      "        num_rows: 2036\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['title', 'summary', 'url', 'paragraphs'],\n",
      "        num_rows: 2143\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Ion Cristoiu: Drama din amor, mai tare decât adoptarea Constituţiei.\n",
      "Summary: ['Ion Cristoiu: În anii 1923-1924, numita Anny Bally din Brăila, \"de o frumuseţe rară“, a încercat să se sinucidă din dragoste. În 8 noiembrie 1924, tot din amor, şi-a împuşcat iubitul, după care s-a împuşcat şi ea.', 'Ion Cristoiu: În tot acest timp, Adunarea Deputaţilor a votat o nouă Constituţie (în 26 noiembrie 1923), considerată \"nulă\" de către Opoziţie; Guvernul liberal Ionel Brătianu a adoptat Pachetul de legi economice, prin care se înfăptuia Programul Prin noi înşine!', 'Ion Cristoiu: Nici unul dintre aceste evenimente, rămase în Istoria Patriei, n-o interesează pe domnişoara Anny, nebună de durere c-a lăsat-o numitul Militeanu, funcţionar din Comerţ. Şi nici pe cititorii celor două mari ziare, Dimineaţa şi Universul ( despărţite de politică, dar unite de suferinţele domnişoarei Anny).']\n",
      "URL: https://alephnews.ro/guvern/ion-cristoiu-drama-din-amor-mai-tare-decat-adoptarea-constitutiei/\n",
      "Paragraphs: ['Scrie Dimineaţa în numărul de luni, 10 noiembrie 1924:\"IMPRESIONANTA DRAMĂ DIN BRĂILAO DOMNIŞOARĂ DESCARCĂ DOUĂ FOCURI REVOLVER ASUPRA IUBITULUI SĂU ŞI APOI SE SINUCIDE.Brăila, 8. – O impresionantă dramă s-a petrecut azi dim. la orele 11 jum. în str. Ştefan cel Mare 265.D-na Anny Bally, de o frumseţe rară, în etate de 22 ani, întreţinea de mai multă vreme relaţiuni amoroase cu tînărul Natan Militeanu, de 26 ani, de profesiune funcţionar comerţ.Din cauza geloziei, Anny îşi propuse să se răzbune pe iubitul ei, care o înşela.Azi dimineaţă pe cînd Militeanu venise la ea, Anny profită de ocazie că erau singuri şi, după o discuţie violentă, a luat un revolver «Browning», pe care-l avea într-un sertar, şi a descărcat asupra sa două focuri rănindu-l grav.Nefericitul tînăr a căzut într-un lac de sînge.Criminala, crezînd că Militeanu a murit, a îndreptat revolverul asupra ei, trăgîndu-şi un glonte în piept.Moartea i-a fost fulgerătoare.La zgomotul produs de detunătura armei, au alergat vecinii.Spectacolul era înfiorător.Camera plină de sînge iar copurile celor doi tineri întinse pe pardoseală.Autorităţile, în frunte cu procurorul d. Berbeciu şi inspectorul poliţienesc Parizescu, au sosit imediat la faţa locului şi au dispus transportarea cadavrului nefericitei Anny Bally la morgă, iar pe Militeanu la spital.Anny, a lăsat două scrisori, ceea ce dovedeşte că era decisă să comită disperatul act încă mai dinainte.O scrisoare era adresată prietenei sale Anny Schvartz, iar a două «către cei ce-mi sînt dragi şi aproape de mine».În această scrisoare, ea cere iertarea şi arată cu amănunţime cauzele cari au determinat-o să facă actul disperat.Zguduitoarea dramă a produs o profundă impresie în întregul oraş unde tineri erau bine cunoscuţi.Anny Bally era singurul sprijin al familiei sale numeroase“.Universul din 12 noiembrie 1924 consacră dramei un spaţiu mult mai larg:\"În jurul dramei amoroase din BrăilaAncheta în privinţa dramei amoroase petrecute în ziua de 8 Noembrie în localitate şi a cărei eroină este d-ra Anny Bally nu s-a terminat încă. Din informaţiile pe cari le-am cules reiese că d-ra Bally întreţinea relaţiuni de dragoste cu tînărul Nathan Militeanu încă de acum 5 ani jumătate, pe cînd locuiau amîndoi pe str. Rahovei, unde îi despărţeau doar cîteva case.Anny Bally, fată serioasă şi foarte frumoasă, prinsese o adîncă simpatie pentru tînărul Militeanu. Cu timpul această iubire devenise atît de cordială, încît tînăra aspira să aranjeze o căsnicie cu tînărul Militeanu. Acesta, văzînd că legăturile de dragoste iau un caracter serios, a căutat ca să se debaraseze de iubita lui cu timpul. Sîmburele geloziei se sădise în inima Annei. La mici intervale surveneau certuri şi scene pline de reproşuri. Într-una din zile, Militeanu, profitînd de acest fapt, mărturisi iubitei sale că se va retrage, urmînd să se logodească cu o tînără fată cu avere. Desnădăjduită că va fi părăsită, tînăra fată a căutat prin diferite mijloace să-l readucă la sentimente mai bune pe iubitul ei. Toate silinţele au rămas însă zadarnice. Acum un an, Anny a încercat să se sinucidă prin strangulare, iar acum în urmă să se otrăvească. Militeanu aflînd despre aceste încercări, a revenit lîngă iubita lui, dar pentru scurt timp, pentru ca mai tîrziu să găsească un mijloc ca să se debaraseze pentru totdeauna de ea. Totul părea un timp că s-a dat uitării. Anny mărturisea prietenelor ei că va duce o nouă viaţă, dar împrejurările au fost mai tari ca voinţa ei. Tînăra fată nu putea să dea uitării pe acela pe care-l iubise atît de mult În intervalul acesta se iveşte un tînăr pretendent la mîna Annei. Ea nu i-a dat nici un răspuns. Peste puţin timp, tînărul pleacă în America, de unde îi scrie că dacă vrea să devie fericită să-l urmeze. Fie din cauza lipsei de bani, fie că Anny nu putea uita pe Militeanu, n-a răspuns propunerilor lui.Într-o zi tînăra Anny reuşi să-şi procure un revolver.Acum cîteva zile a sosit în localitate logodnica lui Militeanu. Anny aflînd şi fiind sigură că partida este pierdută, a încercat să-şi joace ultima carte. Sîmbătă, 8 noiembrie, dimineaţă, pe la orele 8, tînărul Militeanu primeşte un bilet din partea Anei în care îi spune: «Te rog, vino imediat, am să-ţi comunic ceva foarte important, în interesul tău; te aştept Anny».Militeanu, fără să bănuiască intenţia fostei sale iubite, s-a dus la locuinţa ei din strada Ştefan cel Mare, unde a fost primit imediat. Anny a rugat pe mama ei, care tocmai în dimineaţa aceia venise de la Galaţi, să-i lase singuri, deoarece au de aranjat chestiune serioase. Rămasă singură, Anny i-a reamintit lui Militeanu că are anumite obligaţiuni faţă de dînsa şi dacă este dispus să-şi ţie angajamentul. Acesta nu numai că a refuzat, dar i-a spus Annei că legăturile dintre ei sînt terminate.Atunci Anny, nebună de durere, a scos revolverul «Browning» şi a tras asupra lui Militeanu, rănindu-l grav. Crezînd că victima a murit, cu aceiaşi armă şi-a descărcat un foc în piept, moarte fiindu-i fulgerătoare.Starea lui Nathan Militeanu, care se află la spital, continuă să fie foarte gravă. Eri s-a procedat la extragerea glonţului“.În anii 1923-1924, numita Anny Bally din Brăila, \"de o frumuseţe rară“, a încercat să se sinucidă din dragoste.În 8 noiembrie 1924, tot din amor, şi-a împuşcat iubitul, după care s-a împuşcat şi ea.În tot acest timp, Adunarea Deputaţilor a votat o nouă Constituţie (în 26 noiembrie 1923), considerată \"nulă\" de către Opoziţie; Guvernul liberal Ionel Brătianu a adoptat Pachetul de legi economice, prin care se înfăptuia Programul Prin noi înşine! ; Toate ziarele scriu despre o nouă afacere de corupţie la nivel înalt: cea a Paşapoartelor; Pe 11 mai 1924, apare un nou partid: Partidul Naţionalist al Poporului, condus de Nicolae Iorga.Despre aceste evenimente se discută pătimaş în Parlament, în cafenele, ziarele le relatează sub titluri uriaşe, plasate pe prima pagină.Nici unul dintre aceste evenimente, rămase în Istoria Patriei, n-o interesează pe domnişoara Anny, nebună de durere c-a lăsat-o numitul Militeanu, funcţionar din Comerţ.Şi nici pe cititorii celor două mari ziare, Dimineaţa şi Universul ( despărţite de politică, dar unite de suferinţele domnişoarei Anny), care cumpără pe rupte şi parcurg febril amplele articole dedicate celor \" două focuri de revolver descărcate asupra iubitului\".Şi cînd te gîndeşti că mulţi îşi bat capul şi azi cu întrebarea:De ce nu ies românii la vot?NOTĂ: Acest editorial este preluat integral de pe cristoiublog.ro.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Title:\", dataset['train'][0]['title'])\n",
    "print(\"Summary:\", dataset['train'][0]['summary'])\n",
    "print(\"URL:\", dataset['train'][0]['url'])\n",
    "print(\"Paragraphs:\", dataset['train'][0]['paragraphs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.13.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2023.11.17)\n",
      "Using cached transformers-4.40.0-py3-none-any.whl (9.0 MB)\n",
      "Downloading safetensors-0.4.3-cp311-none-win_amd64.whl (287 kB)\n",
      "   ---------------------------------------- 0.0/287.3 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 20.5/287.3 kB 640.0 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 215.0/287.3 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 287.3/287.3 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.8/2.2 MB 15.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.6/2.2 MB 17.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 15.7 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, tokenizers, transformers\n",
      "Successfully installed safetensors-0.4.3 tokenizers-0.19.1 transformers-4.40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.2.2-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.17.2-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.2.2-cp311-cp311-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torch-2.2.2-cp311-cp311-win_amd64.whl (198.6 MB)\n",
      "   ---------------------------------------- 0.0/198.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/198.6 MB 5.9 MB/s eta 0:00:34\n",
      "   ---------------------------------------- 0.7/198.6 MB 8.7 MB/s eta 0:00:23\n",
      "   ---------------------------------------- 1.3/198.6 MB 10.5 MB/s eta 0:00:19\n",
      "   ---------------------------------------- 2.0/198.6 MB 11.9 MB/s eta 0:00:17\n",
      "    --------------------------------------- 2.8/198.6 MB 13.8 MB/s eta 0:00:15\n",
      "    --------------------------------------- 3.6/198.6 MB 14.3 MB/s eta 0:00:14\n",
      "    --------------------------------------- 4.6/198.6 MB 15.4 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 5.6/198.6 MB 16.3 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 6.3/198.6 MB 16.8 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 7.3/198.6 MB 16.7 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 8.2/198.6 MB 16.9 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 9.2/198.6 MB 17.3 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 10.2/198.6 MB 17.7 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 11.7/198.6 MB 20.5 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 12.7/198.6 MB 21.9 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 14.1/198.6 MB 22.6 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 15.3/198.6 MB 24.2 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 16.7/198.6 MB 26.2 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 17.4/198.6 MB 26.2 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 18.2/198.6 MB 26.2 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 19.3/198.6 MB 24.2 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 21.2/198.6 MB 26.2 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 23.0/198.6 MB 28.4 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 25.2/198.6 MB 31.2 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 26.9/198.6 MB 32.7 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 28.5/198.6 MB 38.6 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 30.2/198.6 MB 38.6 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 31.9/198.6 MB 38.6 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 33.5/198.6 MB 38.5 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 34.7/198.6 MB 34.4 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 36.4/198.6 MB 34.4 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 38.5/198.6 MB 34.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 40.5/198.6 MB 38.5 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 42.1/198.6 MB 38.5 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 43.7/198.6 MB 38.5 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 45.8/198.6 MB 40.9 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 47.5/198.6 MB 40.9 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 48.8/198.6 MB 38.6 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 51.0/198.6 MB 38.6 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 52.3/198.6 MB 36.4 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 54.4/198.6 MB 38.5 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 56.2/198.6 MB 38.5 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 58.0/198.6 MB 40.9 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 58.7/198.6 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 61.9/198.6 MB 43.5 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 64.1/198.6 MB 43.5 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 64.5/198.6 MB 43.7 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 66.9/198.6 MB 38.6 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 69.3/198.6 MB 50.4 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 70.1/198.6 MB 46.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 71.9/198.6 MB 38.6 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 73.9/198.6 MB 36.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 75.2/198.6 MB 40.9 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 75.8/198.6 MB 38.6 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 78.0/198.6 MB 34.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 79.1/198.6 MB 31.2 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 80.4/198.6 MB 32.7 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 81.7/198.6 MB 29.7 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 83.2/198.6 MB 29.8 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 84.5/198.6 MB 28.5 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 85.7/198.6 MB 28.5 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 86.4/198.6 MB 28.5 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 87.0/198.6 MB 25.2 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 87.4/198.6 MB 23.4 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 88.7/198.6 MB 23.4 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 89.5/198.6 MB 22.5 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 90.6/198.6 MB 22.6 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 91.5/198.6 MB 21.8 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 92.4/198.6 MB 21.1 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 93.3/198.6 MB 19.9 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 93.9/198.6 MB 19.3 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 94.9/198.6 MB 19.3 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 96.1/198.6 MB 19.3 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 97.1/198.6 MB 19.8 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 98.0/198.6 MB 20.5 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 99.1/198.6 MB 21.1 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 100.1/198.6 MB 21.1 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 100.8/198.6 MB 19.9 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 101.7/198.6 MB 20.5 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 102.6/198.6 MB 20.5 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 103.7/198.6 MB 21.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 104.6/198.6 MB 21.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 105.5/198.6 MB 21.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 105.9/198.6 MB 20.5 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 106.8/198.6 MB 19.3 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 107.7/198.6 MB 19.3 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 108.6/198.6 MB 19.2 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 109.6/198.6 MB 19.2 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 110.3/198.6 MB 18.7 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 111.3/198.6 MB 19.3 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 112.0/198.6 MB 18.7 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 112.6/198.6 MB 18.2 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 113.2/198.6 MB 17.7 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 113.6/198.6 MB 17.2 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 114.3/198.6 MB 16.4 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 114.8/198.6 MB 16.0 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 115.5/198.6 MB 16.0 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 116.2/198.6 MB 15.6 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 116.9/198.6 MB 16.0 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 117.6/198.6 MB 15.6 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 118.2/198.6 MB 15.2 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 118.9/198.6 MB 15.2 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 119.6/198.6 MB 14.9 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 120.3/198.6 MB 14.6 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 121.0/198.6 MB 14.2 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 121.8/198.6 MB 14.6 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 122.2/198.6 MB 14.2 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 122.8/198.6 MB 14.2 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 123.5/198.6 MB 14.6 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 124.4/198.6 MB 14.9 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 124.9/198.6 MB 14.9 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 125.6/198.6 MB 14.9 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 126.2/198.6 MB 14.6 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 126.6/198.6 MB 14.6 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 127.4/198.6 MB 14.2 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 128.1/198.6 MB 14.9 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 129.0/198.6 MB 14.9 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 129.8/198.6 MB 14.9 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 130.5/198.6 MB 15.2 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 131.2/198.6 MB 14.9 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 132.0/198.6 MB 15.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 132.9/198.6 MB 16.0 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 133.6/198.6 MB 16.0 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 134.4/198.6 MB 16.0 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 135.2/198.6 MB 16.0 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 136.1/198.6 MB 16.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 136.9/198.6 MB 17.2 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 137.9/198.6 MB 17.7 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 138.7/198.6 MB 17.7 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 139.6/198.6 MB 17.7 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 140.4/198.6 MB 17.7 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 141.2/198.6 MB 18.7 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 141.9/198.6 MB 18.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 142.7/198.6 MB 18.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 143.6/198.6 MB 18.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 144.6/198.6 MB 18.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 145.6/198.6 MB 19.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 146.5/198.6 MB 19.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 147.4/198.6 MB 19.2 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 148.2/198.6 MB 18.7 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 149.0/198.6 MB 18.7 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 149.9/198.6 MB 18.7 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 150.6/198.6 MB 18.7 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 151.6/198.6 MB 18.7 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 152.5/198.6 MB 19.9 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 153.4/198.6 MB 19.9 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 154.2/198.6 MB 19.3 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 155.2/198.6 MB 19.3 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 156.1/198.6 MB 19.3 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 156.8/198.6 MB 19.2 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 157.6/198.6 MB 18.7 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 158.3/198.6 MB 18.2 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 159.2/198.6 MB 18.7 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 160.1/198.6 MB 18.7 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 161.0/198.6 MB 18.7 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 161.6/198.6 MB 18.2 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 162.5/198.6 MB 18.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 163.5/198.6 MB 18.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 164.5/198.6 MB 18.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 165.4/198.6 MB 18.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 166.1/198.6 MB 18.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 167.1/198.6 MB 19.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 168.0/198.6 MB 19.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 169.0/198.6 MB 19.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 169.9/198.6 MB 19.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 171.0/198.6 MB 19.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 172.1/198.6 MB 20.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 172.8/198.6 MB 20.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 173.6/198.6 MB 20.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 174.5/198.6 MB 19.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 175.6/198.6 MB 19.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 176.2/198.6 MB 19.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 177.3/198.6 MB 19.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 178.3/198.6 MB 20.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 179.0/198.6 MB 19.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 179.9/198.6 MB 19.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 180.9/198.6 MB 19.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 181.6/198.6 MB 19.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 182.5/198.6 MB 19.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 183.3/198.6 MB 18.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 184.2/198.6 MB 19.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 185.2/198.6 MB 19.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 185.9/198.6 MB 18.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 186.9/198.6 MB 19.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 188.1/198.6 MB 19.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 189.0/198.6 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 190.1/198.6 MB 19.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 191.1/198.6 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 192.1/198.6 MB 21.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 192.8/198.6 MB 20.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  193.7/198.6 MB 21.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  194.5/198.6 MB 20.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  195.3/198.6 MB 20.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  196.1/198.6 MB 20.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  196.7/198.6 MB 19.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  197.5/198.6 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.3/198.6 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------- 198.6/198.6 MB 11.9 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.17.2-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 0.9/1.2 MB 28.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 18.3 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.2.2-cp311-cp311-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 1.0/2.4 MB 30.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.8/2.4 MB 23.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 21.7 MB/s eta 0:00:00\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.2.2 torchaudio-2.2.2 torchvision-0.17.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Concatenate paragraphs into one string if it's a list of strings\n",
    "    inputs = [' '.join(paragraphs) if isinstance(paragraphs, list) else paragraphs for paragraphs in examples['paragraphs']]\n",
    "    \n",
    "    # Also concatenate summaries into one string if it's a list of strings\n",
    "    summaries = [' '.join(summary) if isinstance(summary, list) else summary for summary in examples['summary']]\n",
    "\n",
    "    # Tokenize inputs and labels without specifying return_tensors to keep output in native list/dictionary format\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer(summaries, max_length=128, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "\n",
    "dataset = dataset.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['title', 'summary', 'url', 'paragraphs', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 38683\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove title and url from the dataset\n",
    "\n",
    "def remove_title_url(example):\n",
    "    del example['title']\n",
    "    del example['url']\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(remove_title_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['summary', 'paragraphs', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 38683\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\rog\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (5.9.7)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (2.2.2)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: requests in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\rog\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (4.37.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from transformers[torch]) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from transformers[torch]) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from transformers[torch]) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from transformers[torch]) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\rog\\appdata\\roaming\\python\\python310\\site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from transformers[torch]) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from transformers[torch]) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from transformers[torch]) (4.65.0)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.11 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from transformers[torch]) (2.1.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from transformers[torch]) (0.29.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rog\\appdata\\roaming\\python\\python310\\site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rog\\appdata\\roaming\\python\\python310\\site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from requests->transformers[torch]) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rog\\appdata\\roaming\\python\\python310\\site-packages (from requests->transformers[torch]) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from jinja2->torch!=1.12.0,>=1.11->transformers[torch]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from sympy->torch!=1.12.0,>=1.11->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: accelerate in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from accelerate) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from accelerate) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from torch>=1.10.0->accelerate) (2023.12.2)\n",
      "Requirement already satisfied: requests in c:\\users\\rog\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rog\\appdata\\roaming\\python\\python310\\site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rog\\appdata\\roaming\\python\\python310\\site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rog\\appdata\\roaming\\python\\python310\\site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\rog\\anaconda3\\envs\\pythonrl\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch]\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RoG\\anaconda3\\envs\\pythonRL\\lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n",
      "  0%|          | 0/750 [00:00<?, ?it/s]c:\\Users\\RoG\\anaconda3\\envs\\pythonRL\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:590: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "                                                   \n",
      " 33%|███▎      | 250/750 [58:30<1:45:43, 12.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9561969041824341, 'eval_runtime': 335.4326, 'eval_samples_per_second': 1.491, 'eval_steps_per_second': 0.745, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 500/750 [1:51:20<52:51, 12.69s/it]  Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1853, 'learning_rate': 6.720000000000001e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 67%|██████▋   | 500/750 [1:57:01<52:51, 12.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9243336319923401, 'eval_runtime': 334.1019, 'eval_samples_per_second': 1.497, 'eval_steps_per_second': 0.748, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "100%|██████████| 750/750 [2:55:24<00:00, 14.03s/it]\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9325523972511292, 'eval_runtime': 335.1293, 'eval_samples_per_second': 1.492, 'eval_steps_per_second': 0.746, 'epoch': 3.0}\n",
      "{'train_runtime': 10524.3314, 'train_samples_per_second': 0.285, 'train_steps_per_second': 0.071, 'train_loss': 1.0742976684570313, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./bart_model_large\\\\tokenizer_config.json',\n",
       " './bart_model_large\\\\special_tokens_map.json',\n",
       " './bart_model_large\\\\vocab.json',\n",
       " './bart_model_large\\\\merges.txt',\n",
       " './bart_model_large\\\\added_tokens.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, Trainer, TrainingArguments\n",
    "\n",
    "# model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_large\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,  \n",
    "    gradient_accumulation_steps=2, \n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "\n",
    "train_subset = dataset['train'].select(range(1000))  # Example: select first 1000 samples\n",
    "validation_subset = dataset['validation'].select(range(500))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_subset,\n",
    "    eval_dataset=validation_subset\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "model_path = \"./bart_model_large\"\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./bart_model\\\\tokenizer_config.json',\n",
       " './bart_model\\\\special_tokens_map.json',\n",
       " './bart_model\\\\vocab.json',\n",
       " './bart_model\\\\merges.txt',\n",
       " './bart_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"./bart_model_large\"\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1072/1072 [23:50<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9582434296607971, 'eval_runtime': 1431.8665, 'eval_samples_per_second': 1.497, 'eval_steps_per_second': 0.749, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate(dataset['test'])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is using: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available and then move the model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"Model is using:\", device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_summary(text):\n",
    "    # Assuming `text` is a single string of text.\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "    # Move tensor to the same device as model\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    summary_ids = model.generate(inputs[\"input_ids\"], num_beams=4, max_length=200, early_stopping=True)\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: ['De astăzi, spitalele au noi proceduri pentru internarea și circuitul pacienților suspecți sau bolnavi de COVID. Pacienții asimptomatici, care stau în izolare acasă, nu mai trebuie să se retesteze după cele 14 zile, iar vindecarea lor este stabilită de medicii de familie.În noul ordin al Ministrului Sănătății sunt reguli mai clare pentru DSP-uri când vine vorba de situații de risc epidemiologic. Cel mai important aspect din document este stabilirea traseului pacientului confirmat pozitiv.\"Pacientul care nu se simte bine va trebui să stea acasă, apoi să sune la 112 și la medicul de familie. O ambulanță îl va prelua și îl va duce la o unitate medicală unde va fi evaluat. Dacă are simptome grave, va fi internat, unde i se vor acorda îngrijiri medicale și i se va face testul Covid. Dacă în schimb are simptome uzuale, cei de la DSP îi vor face testul, iar apoi tot DSP îi va spune dacă este infectat sau nu.Pacienții care sunt confirmați pozitiv vor fi redirecționați către ambulanță care îi va transporta la spital.Pacientul care prezintă simptomatologie Covid, iar medicul poate să vadă asta la un computer tomograf, chiar daca testul e negativ, va fi tartat exact ca un pacient infectat, urmând ca testul să fie repetat după 48 de ore.În ceea ce privește pacientul asimptomatic, acesta va fi izolat fie acasă, fie la spital, dar asta rămâne la latitudinea medicului\", a explicat Ana Maria Rus, corespondent Aleph News.']\n",
      "Generated summary: De astăzi, spitalele au noi proceduri pentru internarea și circuitul pacienților suspecți sau bolnavi de COVID. Pacienţii asimptomatici, care stau în izolare acasă, nu mai trebuie să se retesteze după cele 14 zile, iar vindecarea lor este stabilită de medic\n",
      "Actual summary: ['Pacienții asimptomatici, care stau în izolare acasă, nu mai trebuie să se retesteze după cele 14 zile.', 'Medicii de familie sunt cei care stabilesc dacă pacienții asimptomatici sunt vindecați.', 'Cel mai important aspect din document este stabilirea traseului pacientului confirmat pozitiv.']\n"
     ]
    }
   ],
   "source": [
    "text_number = 7\n",
    "test_text = dataset['test'][text_number]['paragraphs']\n",
    "summary = generate_summary(test_text)\n",
    "\n",
    "print(\"Original text:\", test_text)\n",
    "\n",
    "print(\"Generated summary:\", summary)\n",
    "\n",
    "print(\"Actual summary:\", dataset['test'][text_number]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RoG\\anaconda3\\envs\\pythonRL\\lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n",
      "  1%|          | 10/1500 [01:59<5:37:49, 13.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4211, 'learning_rate': 9e-07, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 20/1500 [04:18<5:43:17, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3921, 'learning_rate': 1.9e-06, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 30/1500 [06:37<5:41:07, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4129, 'learning_rate': 2.9e-06, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 40/1500 [08:57<5:38:52, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2301, 'learning_rate': 3.9e-06, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 50/1500 [11:16<5:36:30, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8931, 'learning_rate': 4.9000000000000005e-06, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 60/1500 [13:35<5:34:04, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5071, 'learning_rate': 5.9e-06, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 70/1500 [15:55<5:31:55, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7109, 'learning_rate': 6.900000000000001e-06, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 80/1500 [18:14<5:29:39, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7457, 'learning_rate': 7.9e-06, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 90/1500 [20:33<5:27:24, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.536, 'learning_rate': 8.9e-06, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 100/1500 [22:52<5:24:55, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5924, 'learning_rate': 9.900000000000002e-06, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 110/1500 [25:12<5:22:45, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5281, 'learning_rate': 1.09e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 120/1500 [27:29<5:19:30, 13.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3629, 'learning_rate': 1.18e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 130/1500 [29:48<5:17:57, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3346, 'learning_rate': 1.2800000000000001e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 140/1500 [32:08<5:15:44, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2852, 'learning_rate': 1.3800000000000002e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 150/1500 [34:27<5:13:25, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3084, 'learning_rate': 1.48e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 160/1500 [36:46<5:10:56, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3018, 'learning_rate': 1.58e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 170/1500 [39:06<5:08:35, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4852, 'learning_rate': 1.6800000000000002e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 180/1500 [41:25<5:06:19, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1451, 'learning_rate': 1.78e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 190/1500 [43:44<5:03:58, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2775, 'learning_rate': 1.88e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 200/1500 [46:03<5:01:39, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2858, 'learning_rate': 1.9800000000000004e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 210/1500 [48:22<4:59:13, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1014, 'learning_rate': 2.08e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 220/1500 [50:42<4:57:01, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5111, 'learning_rate': 2.18e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 230/1500 [53:01<4:54:44, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2783, 'learning_rate': 2.2800000000000002e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 240/1500 [55:20<4:52:23, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3622, 'learning_rate': 2.38e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 250/1500 [57:39<4:49:57, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3311, 'learning_rate': 2.48e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 260/1500 [59:59<4:47:38, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3795, 'learning_rate': 2.58e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 270/1500 [1:02:18<4:45:20, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2128, 'learning_rate': 2.6800000000000004e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 280/1500 [1:04:37<4:43:01, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2537, 'learning_rate': 2.7800000000000005e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 290/1500 [1:06:56<4:40:48, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0776, 'learning_rate': 2.88e-05, 'epoch': 0.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 300/1500 [1:09:16<4:38:41, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4504, 'learning_rate': 2.98e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 310/1500 [1:11:35<4:36:10, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3134, 'learning_rate': 3.08e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 320/1500 [1:13:54<4:33:54, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1889, 'learning_rate': 3.18e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 330/1500 [1:16:13<4:31:25, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2623, 'learning_rate': 3.2800000000000004e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 340/1500 [1:18:33<4:29:13, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3233, 'learning_rate': 3.38e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 350/1500 [1:20:52<4:26:51, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0705, 'learning_rate': 3.48e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 360/1500 [1:23:11<4:24:33, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3018, 'learning_rate': 3.58e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 370/1500 [1:25:30<4:22:17, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3172, 'learning_rate': 3.68e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 380/1500 [1:27:50<4:19:52, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0686, 'learning_rate': 3.7800000000000004e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 390/1500 [1:30:09<4:17:31, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2893, 'learning_rate': 3.88e-05, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 400/1500 [1:32:28<4:15:11, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.423, 'learning_rate': 3.9800000000000005e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 410/1500 [1:34:47<4:12:57, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0682, 'learning_rate': 4.08e-05, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 420/1500 [1:37:06<4:10:37, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2872, 'learning_rate': 4.18e-05, 'epoch': 0.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 430/1500 [1:39:26<4:08:15, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2342, 'learning_rate': 4.2800000000000004e-05, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 440/1500 [1:41:45<4:05:56, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4806, 'learning_rate': 4.38e-05, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 450/1500 [1:44:04<4:03:40, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3665, 'learning_rate': 4.4800000000000005e-05, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 460/1500 [1:46:23<4:01:23, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3017, 'learning_rate': 4.58e-05, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 470/1500 [1:48:43<3:58:53, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3668, 'learning_rate': 4.6800000000000006e-05, 'epoch': 0.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 480/1500 [1:51:02<3:56:40, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6067, 'learning_rate': 4.78e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 490/1500 [1:53:21<3:54:26, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1928, 'learning_rate': 4.88e-05, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 500/1500 [1:55:40<3:52:05, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1673, 'learning_rate': 4.9800000000000004e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      " 33%|███▎      | 500/1500 [2:08:25<3:52:05, 13.93s/it]Checkpoint destination directory ./results_large\\checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0821099281311035, 'eval_runtime': 764.1034, 'eval_samples_per_second': 1.309, 'eval_steps_per_second': 0.654, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 510/1500 [2:10:54<6:24:13, 23.29s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1124, 'learning_rate': 4.96e-05, 'epoch': 1.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 520/1500 [2:13:13<3:51:42, 14.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.022, 'learning_rate': 4.91e-05, 'epoch': 1.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 530/1500 [2:15:32<3:45:05, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9501, 'learning_rate': 4.86e-05, 'epoch': 1.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 540/1500 [2:17:51<3:42:38, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0143, 'learning_rate': 4.8100000000000004e-05, 'epoch': 1.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 550/1500 [2:20:10<3:40:21, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.302, 'learning_rate': 4.76e-05, 'epoch': 1.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 560/1500 [2:22:30<3:38:01, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2471, 'learning_rate': 4.71e-05, 'epoch': 1.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 570/1500 [2:24:49<3:35:30, 13.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3117, 'learning_rate': 4.660000000000001e-05, 'epoch': 1.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 580/1500 [2:27:08<3:33:21, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1228, 'learning_rate': 4.61e-05, 'epoch': 1.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 590/1500 [2:29:27<3:31:26, 13.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0649, 'learning_rate': 4.5600000000000004e-05, 'epoch': 1.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 600/1500 [2:31:46<3:28:47, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0789, 'learning_rate': 4.5100000000000005e-05, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 610/1500 [2:34:05<3:26:23, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3543, 'learning_rate': 4.46e-05, 'epoch': 1.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 620/1500 [2:36:25<3:24:02, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9715, 'learning_rate': 4.41e-05, 'epoch': 1.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 630/1500 [2:38:44<3:21:45, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0544, 'learning_rate': 4.36e-05, 'epoch': 1.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 640/1500 [2:41:03<3:19:28, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3041, 'learning_rate': 4.3100000000000004e-05, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 650/1500 [2:43:22<3:17:14, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1362, 'learning_rate': 4.26e-05, 'epoch': 1.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 660/1500 [2:45:41<3:14:49, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2135, 'learning_rate': 4.21e-05, 'epoch': 1.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 670/1500 [2:48:00<3:12:31, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0914, 'learning_rate': 4.16e-05, 'epoch': 1.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 680/1500 [2:50:20<3:10:10, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.953, 'learning_rate': 4.11e-05, 'epoch': 1.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 690/1500 [2:52:39<3:07:50, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3129, 'learning_rate': 4.0600000000000004e-05, 'epoch': 1.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 700/1500 [2:54:58<3:05:35, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2437, 'learning_rate': 4.0100000000000006e-05, 'epoch': 1.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 710/1500 [2:57:17<3:03:11, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8854, 'learning_rate': 3.960000000000001e-05, 'epoch': 1.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 720/1500 [2:59:36<3:00:53, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0481, 'learning_rate': 3.91e-05, 'epoch': 1.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 730/1500 [3:01:56<2:58:38, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0812, 'learning_rate': 3.86e-05, 'epoch': 1.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 740/1500 [3:04:15<2:56:15, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2417, 'learning_rate': 3.8100000000000005e-05, 'epoch': 1.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 750/1500 [3:06:34<2:53:58, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8377, 'learning_rate': 3.76e-05, 'epoch': 1.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 760/1500 [3:08:53<2:51:34, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9638, 'learning_rate': 3.71e-05, 'epoch': 1.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 770/1500 [3:11:12<2:49:20, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1886, 'learning_rate': 3.66e-05, 'epoch': 1.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 780/1500 [3:13:31<2:47:04, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0152, 'learning_rate': 3.61e-05, 'epoch': 1.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 790/1500 [3:15:51<2:44:41, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1989, 'learning_rate': 3.56e-05, 'epoch': 1.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 800/1500 [3:18:10<2:42:19, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4186, 'learning_rate': 3.51e-05, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 810/1500 [3:20:29<2:40:00, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0504, 'learning_rate': 3.46e-05, 'epoch': 1.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 820/1500 [3:22:48<2:37:43, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1204, 'learning_rate': 3.41e-05, 'epoch': 1.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 830/1500 [3:25:07<2:35:23, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0255, 'learning_rate': 3.3600000000000004e-05, 'epoch': 1.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 840/1500 [3:27:26<2:33:03, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0615, 'learning_rate': 3.3100000000000005e-05, 'epoch': 1.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 850/1500 [3:29:46<2:30:47, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9897, 'learning_rate': 3.26e-05, 'epoch': 1.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 860/1500 [3:32:05<2:28:25, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0068, 'learning_rate': 3.21e-05, 'epoch': 1.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 870/1500 [3:34:24<2:26:08, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0376, 'learning_rate': 3.16e-05, 'epoch': 1.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 880/1500 [3:36:43<2:23:49, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0173, 'learning_rate': 3.1100000000000004e-05, 'epoch': 1.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 890/1500 [3:39:02<2:21:29, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2388, 'learning_rate': 3.06e-05, 'epoch': 1.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 900/1500 [3:41:22<2:19:12, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0779, 'learning_rate': 3.01e-05, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 910/1500 [3:43:41<2:16:52, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9574, 'learning_rate': 2.96e-05, 'epoch': 1.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 920/1500 [3:46:00<2:14:28, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9781, 'learning_rate': 2.91e-05, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 930/1500 [3:48:19<2:12:13, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9954, 'learning_rate': 2.86e-05, 'epoch': 1.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 940/1500 [3:50:38<2:09:51, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9175, 'learning_rate': 2.8100000000000005e-05, 'epoch': 1.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 950/1500 [3:52:57<2:07:35, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2093, 'learning_rate': 2.7600000000000003e-05, 'epoch': 1.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 960/1500 [3:55:17<2:05:12, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9626, 'learning_rate': 2.7100000000000005e-05, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 970/1500 [3:57:36<2:02:55, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2424, 'learning_rate': 2.6600000000000003e-05, 'epoch': 1.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 980/1500 [3:59:55<2:00:48, 13.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8867, 'learning_rate': 2.61e-05, 'epoch': 1.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 990/1500 [4:02:14<1:58:18, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0678, 'learning_rate': 2.5600000000000002e-05, 'epoch': 1.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1000/1500 [4:04:33<1:55:57, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1152, 'learning_rate': 2.51e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      " 67%|██████▋   | 1000/1500 [4:17:17<1:55:57, 13.91s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9899989366531372, 'eval_runtime': 763.706, 'eval_samples_per_second': 1.309, 'eval_steps_per_second': 0.655, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1010/1500 [4:19:43<3:09:48, 23.24s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8244, 'learning_rate': 2.46e-05, 'epoch': 2.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 1020/1500 [4:22:02<1:53:22, 14.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8673, 'learning_rate': 2.41e-05, 'epoch': 2.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 1030/1500 [4:24:21<1:49:03, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7351, 'learning_rate': 2.36e-05, 'epoch': 2.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 1040/1500 [4:26:40<1:46:43, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8122, 'learning_rate': 2.3100000000000002e-05, 'epoch': 2.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 1050/1500 [4:29:00<1:44:24, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7856, 'learning_rate': 2.26e-05, 'epoch': 2.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 1060/1500 [4:31:19<1:42:06, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8103, 'learning_rate': 2.2100000000000002e-05, 'epoch': 2.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 1070/1500 [4:33:38<1:39:46, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7118, 'learning_rate': 2.16e-05, 'epoch': 2.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1080/1500 [4:35:57<1:37:23, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8112, 'learning_rate': 2.11e-05, 'epoch': 2.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1090/1500 [4:38:16<1:35:05, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7494, 'learning_rate': 2.06e-05, 'epoch': 2.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1100/1500 [4:40:36<1:32:46, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8084, 'learning_rate': 2.01e-05, 'epoch': 2.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 1110/1500 [4:42:55<1:30:28, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7567, 'learning_rate': 1.9600000000000002e-05, 'epoch': 2.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 1120/1500 [4:45:14<1:28:07, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7221, 'learning_rate': 1.91e-05, 'epoch': 2.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 1130/1500 [4:47:33<1:25:48, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.73, 'learning_rate': 1.86e-05, 'epoch': 2.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 1140/1500 [4:49:52<1:23:28, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9081, 'learning_rate': 1.81e-05, 'epoch': 2.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1150/1500 [4:52:11<1:21:10, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.751, 'learning_rate': 1.76e-05, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1160/1500 [4:54:31<1:18:52, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7238, 'learning_rate': 1.7100000000000002e-05, 'epoch': 2.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1170/1500 [4:56:50<1:16:32, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8719, 'learning_rate': 1.66e-05, 'epoch': 2.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 1180/1500 [4:59:09<1:14:14, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.826, 'learning_rate': 1.6100000000000002e-05, 'epoch': 2.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 1190/1500 [5:01:28<1:11:55, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6641, 'learning_rate': 1.56e-05, 'epoch': 2.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1200/1500 [5:03:47<1:09:34, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9051, 'learning_rate': 1.51e-05, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 1210/1500 [5:06:07<1:07:15, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7587, 'learning_rate': 1.4599999999999999e-05, 'epoch': 2.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 1220/1500 [5:08:26<1:04:57, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8523, 'learning_rate': 1.4099999999999999e-05, 'epoch': 2.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1230/1500 [5:10:45<1:02:38, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7697, 'learning_rate': 1.3600000000000002e-05, 'epoch': 2.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1240/1500 [5:13:04<1:00:18, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7444, 'learning_rate': 1.3100000000000002e-05, 'epoch': 2.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1250/1500 [5:15:23<57:58, 13.91s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8656, 'learning_rate': 1.2600000000000001e-05, 'epoch': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1260/1500 [5:17:42<55:39, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8101, 'learning_rate': 1.2100000000000001e-05, 'epoch': 2.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 1270/1500 [5:20:02<53:22, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.708, 'learning_rate': 1.16e-05, 'epoch': 2.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 1280/1500 [5:22:21<51:01, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7842, 'learning_rate': 1.11e-05, 'epoch': 2.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 1290/1500 [5:24:40<48:41, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9012, 'learning_rate': 1.06e-05, 'epoch': 2.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1300/1500 [5:26:59<46:24, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6743, 'learning_rate': 1.0100000000000002e-05, 'epoch': 2.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1310/1500 [5:29:18<44:04, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7238, 'learning_rate': 9.600000000000001e-06, 'epoch': 2.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1320/1500 [5:31:38<41:45, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8018, 'learning_rate': 9.100000000000001e-06, 'epoch': 2.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 1330/1500 [5:33:57<39:24, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.868, 'learning_rate': 8.599999999999999e-06, 'epoch': 2.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 1340/1500 [5:36:16<37:05, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7188, 'learning_rate': 8.1e-06, 'epoch': 2.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 1350/1500 [5:38:35<34:48, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7353, 'learning_rate': 7.6e-06, 'epoch': 2.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 1360/1500 [5:40:54<32:28, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6357, 'learning_rate': 7.1e-06, 'epoch': 2.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 1370/1500 [5:43:13<30:09, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9176, 'learning_rate': 6.6e-06, 'epoch': 2.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1380/1500 [5:45:33<27:49, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5783, 'learning_rate': 6.1e-06, 'epoch': 2.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1390/1500 [5:47:52<25:31, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7846, 'learning_rate': 5.600000000000001e-06, 'epoch': 2.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1400/1500 [5:50:11<23:12, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6628, 'learning_rate': 5.1e-06, 'epoch': 2.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1410/1500 [5:52:30<20:52, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7569, 'learning_rate': 4.6e-06, 'epoch': 2.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 1420/1500 [5:54:49<18:33, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7052, 'learning_rate': 4.1000000000000006e-06, 'epoch': 2.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 1430/1500 [5:57:09<16:14, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7021, 'learning_rate': 3.6e-06, 'epoch': 2.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1440/1500 [5:59:28<13:55, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.967, 'learning_rate': 3.1e-06, 'epoch': 2.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1450/1500 [6:01:47<11:35, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7606, 'learning_rate': 2.6e-06, 'epoch': 2.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1460/1500 [6:04:06<09:16, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.635, 'learning_rate': 2.1000000000000002e-06, 'epoch': 2.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1470/1500 [6:06:25<06:57, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7131, 'learning_rate': 1.6000000000000001e-06, 'epoch': 2.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 1480/1500 [6:08:44<04:38, 13.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7628, 'learning_rate': 1.1e-06, 'epoch': 2.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 1490/1500 [6:11:04<02:19, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8187, 'learning_rate': 6.000000000000001e-07, 'epoch': 2.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [6:13:23<00:00, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0053, 'learning_rate': 1.0000000000000001e-07, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "100%|██████████| 1500/1500 [6:26:07<00:00, 13.93s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.969994068145752, 'eval_runtime': 763.8478, 'eval_samples_per_second': 1.309, 'eval_steps_per_second': 0.655, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n",
      "100%|██████████| 1500/1500 [6:26:18<00:00, 15.45s/it]\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 23178.0549, 'train_samples_per_second': 0.259, 'train_steps_per_second': 0.065, 'train_loss': 1.0995992345809937, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./bart_model_large_2000\\\\tokenizer_config.json',\n",
       " './bart_model_large_2000\\\\special_tokens_map.json',\n",
       " './bart_model_large_2000\\\\vocab.json',\n",
       " './bart_model_large_2000\\\\merges.txt',\n",
       " './bart_model_large_2000\\\\added_tokens.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_large\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,  # Slightly increase learning rate\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=500,  # Add warmup steps\n",
    "    fp16=True,\n",
    "    logging_dir='./logs',  # Enable logging for monitoring\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",  # Save the model at the end of each epoch\n",
    "    load_best_model_at_end=True,  # Load the best model at the end of training based on validation loss\n",
    "    metric_for_best_model='loss',  # Use loss to determine the best model\n",
    "    greater_is_better=False\n",
    ")\n",
    "\n",
    "train_subset = dataset['train'].select(range(2000))  # Use more data if possible\n",
    "validation_subset = dataset['validation'].select(range(1000))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_subset,\n",
    "    eval_dataset=validation_subset\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "model_path = \"./bart_model_large_2000\"\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "\n",
    "from transformers import BartForConditionalGeneration, Trainer, TrainingArguments, BartTokenizer\n",
    "\n",
    "model_path = \"./bart_model_large_2000\"\n",
    "model = BartForConditionalGeneration.from_pretrained(model_path)\n",
    "tokenizer = BartTokenizer.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_summary(text):\n",
    "    # Assuming `text` is a single string of text.\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "    # Move tensor to the same device as model\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    summary_ids = model.generate(inputs[\"input_ids\"], num_beams=4, max_length=200, early_stopping=True)\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RoG\\anaconda3\\envs\\pythonRL\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:590: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: ['Statele Unite și aliații lor se grăbesc să elaboreze planuri de urgență în cazul în care livrările de gaz rusesc, esențiale pentru alimentarea întreprinderilor și încălzirea locuințelor din Europa, vor fi blocate de conflictul din Ucraina.Europa ar avea dificultăți în a supraviețui mult timp fără gaz din partea Rusiei, iar găsirea unor surse alternative reprezintă o provocare logistică uriașă – o realitate care alimentează îngrijorările privind accesul continentului la energie în timpul unei ierni deja dificile.\"Nu există cu adevărat o alternativă rapidă și ușoară\", a declarat Janis Kluge, expert în la Institutul german pentru afaceri internaționale și de securitate.Oficialii de rang înalt de la Casa Albă au declarat reporterilor în această săptămână că discută cu țările și companiile despre accelerarea producției. De asemenea, aceștia încearcă să identifice surse alternative de gaze naturale care ar putea fi redirecționate către Europa.Cu toate acestea, executarea unei intervenții de o asemenea amploare pe piețele energetice ar fi dificilă. Construirea de noi conducte și instalații de lichefiere a gazelor durează ani de zile, iar redirecționarea unor volume mari de combustibil fosil într-un moment în care piața globală și rețelele de transport sunt deja tensionate ar necesita cooperarea marilor exportatori de gaze, cum ar fi Qatar, care s-ar putea să nu aibă prea mult spațiu de manevră.În plus, aprovizionarea cu gaz în Europa este deja supusă unor tensiuni majore. Stocurile scăzute și prețurile ridicate ale gazului au alimentat de luni de zile temerile că, dacă iarna va deveni neobișnuit de rece, țările vor trebui să acorde mai mult ajutor pentru clienții și întreprinderile aflate în dificultate și ar putea chiar să raționalizeze accesul la energie.Nikos Tsafos, expert în energie la Centrul pentru Studii Strategice și Internaționale, a declarat că întreruperile minore ale aprovizionării ar îndoi, dar nu ar rupe sistemul. Cu toate acestea, un scenariu în cel mai rău caz, în care gazul rusesc ar dispărea complet, ar fi o altă poveste.\"O întrerupere a fluxurilor de gaz prin Ucraina este dureroasă, dar gestionabilă\", a declarat Tsafos. \"O întrerupere totală a exporturilor de energie rusească ar fi catastrofală. Europa nu are cum să înlocuiască acele volume într-un mod semnificativ\".']\n",
      "Generated summary: Europa ar avea dificultăți în a supraviețui mult timp fără gaz din partea Rusiei, iar găsirea unor surse alternative reprezintă o provocare logistică uriașă – o realitate care alimentează îngrijorările privind accesul continentului la energie. Întreruperea totală a exporturilor de energie rusești ar fi catastrofală.\n",
      "Actual summary: ['SUA și aliații fac deja planuri de urgență în cazul în care livrările de gaz rusesc ar fi blocate.', 'Fără gazul din partea Rusiei, Europa ar avea dificultăți în a supraviețui.', 'Aprovizionarea cu energie din Europa este deja supusă unor tensiuni majore.']\n"
     ]
    }
   ],
   "source": [
    "text_number = 28\n",
    "test_text = dataset['test'][text_number]['paragraphs']\n",
    "summary = generate_summary(test_text)\n",
    "\n",
    "print(\"Original text:\", test_text)\n",
    "\n",
    "print(\"Generated summary:\", summary)\n",
    "\n",
    "print(\"Actual summary:\", dataset['test'][text_number]['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-win_amd64.whl.metadata (8.3 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   ------------------ -------------------- 471.0/991.5 kB 14.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 991.5/991.5 kB 15.8 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer\n",
    "import torch\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "def preprocess_function_t5(examples):\n",
    "    # Combine the paragraphs into a single string and add the prefix \"summarize:\"\n",
    "    inputs = [\"summarize: \" + \" \".join(doc) for doc in examples['paragraphs']]\n",
    "    \n",
    "    # Summaries may already be a list of strings; concatenate them into one string per example\n",
    "    summaries = [\" \".join(summary) for summary in examples['summary']]\n",
    "\n",
    "    # Use the tokenizer to convert the texts to model inputs\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "    # Tokenize the summaries as well, without the summarize prefix\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(summaries, max_length=128, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "    # Make sure that the labels are tensors and set up for the model\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RoG\\anaconda3\\envs\\pythonRL\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"readerbench/AlephNews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/38683 [00:00<?, ? examples/s]c:\\Users\\RoG\\anaconda3\\envs\\pythonRL\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 38683/38683 [01:11<00:00, 540.30 examples/s]\n",
      "Map: 100%|██████████| 2036/2036 [00:03<00:00, 656.36 examples/s]\n",
      "Map: 100%|██████████| 2143/2143 [00:03<00:00, 664.89 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(preprocess_function_t5, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "c:\\Users\\RoG\\anaconda3\\envs\\pythonRL\\lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n",
      "  7%|▋         | 500/7254 [06:04<1:20:35,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6462, 'learning_rate': 2.7944582299421008e-05, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1000/7254 [12:07<1:14:56,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3616, 'learning_rate': 2.5876757650951198e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1500/7254 [18:10<1:08:52,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3208, 'learning_rate': 2.380893300248139e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2000/7254 [24:17<1:02:40,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3092, 'learning_rate': 2.1741108354011582e-05, 'epoch': 0.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 33%|███▎      | 2418/7254 [29:41<51:30,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.120316505432129, 'eval_runtime': 20.667, 'eval_samples_per_second': 98.515, 'eval_steps_per_second': 6.193, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 2500/7254 [30:40<56:53,  1.39it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2939, 'learning_rate': 1.9673283705541772e-05, 'epoch': 1.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 3000/7254 [36:41<51:55,  1.37it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2763, 'learning_rate': 1.7605459057071963e-05, 'epoch': 1.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 3500/7254 [42:44<45:31,  1.37it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.261, 'learning_rate': 1.553763440860215e-05, 'epoch': 1.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 4000/7254 [48:47<38:50,  1.40it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2686, 'learning_rate': 1.3469809760132341e-05, 'epoch': 1.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 4500/7254 [54:51<33:01,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2401, 'learning_rate': 1.140198511166253e-05, 'epoch': 1.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 67%|██████▋   | 4836/7254 [59:17<25:35,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0944164991378784, 'eval_runtime': 21.5012, 'eval_samples_per_second': 94.692, 'eval_steps_per_second': 5.953, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 5000/7254 [1:01:16<26:53,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.255, 'learning_rate': 9.33829611248966e-06, 'epoch': 2.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 5500/7254 [1:07:21<21:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2368, 'learning_rate': 7.270471464019852e-06, 'epoch': 2.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 6000/7254 [1:13:24<14:56,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2413, 'learning_rate': 5.202646815550041e-06, 'epoch': 2.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 6500/7254 [1:19:27<09:11,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2346, 'learning_rate': 3.134822167080232e-06, 'epoch': 2.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 7000/7254 [1:25:40<03:07,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2313, 'learning_rate': 1.066997518610422e-06, 'epoch': 2.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "100%|██████████| 7254/7254 [1:29:11<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0899014472961426, 'eval_runtime': 21.4596, 'eval_samples_per_second': 94.876, 'eval_steps_per_second': 5.965, 'epoch': 3.0}\n",
      "{'train_runtime': 5351.7239, 'train_samples_per_second': 21.684, 'train_steps_per_second': 1.355, 'train_loss': 1.2966363284750224, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./t5_model_small\\\\tokenizer_config.json',\n",
       " './t5_model_small\\\\special_tokens_map.json',\n",
       " './t5_model_small\\\\spiece.model',\n",
       " './t5_model_small\\\\added_tokens.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "train_dataset = dataset['train']\n",
    "validation_dataset = dataset['validation']\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_t5\",\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    fp16=True,\n",
    "    logging_dir='./logs'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "model_path = \"./t5_model_small\"\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 4\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "# Move model and inputs to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "inputs = inputs.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_path = \"./t5_model_small\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_t5(paragraphs, max_length=150):\n",
    "    # Ensure the device is identified at the start of the function\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # Move the model to the appropriate device\n",
    "    model.to(device)\n",
    "\n",
    "    # Join the list of paragraphs into a single text string\n",
    "    input_text = \" \".join(paragraphs)\n",
    "\n",
    "    # Prefix with 'summarize:' for T5 and tokenize\n",
    "    input_text = \"summarize: \" + input_text\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    # Move the tokenized inputs to the same device as the model\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    # Generate summary ids from the model based on the input\n",
    "    summary_ids = model.generate(inputs, max_length=max_length, length_penalty=2.0, num_beams=6, no_repeat_ngram_size=2, early_stopping=True)\n",
    "\n",
    "\n",
    "    # Decode the summary ids to text\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: Un grup de oameni de știință afirmă că au descoperit din întâmplare ceea ce cred că este cea mai nordică insulă din lume, în largul coastelor Groenlandei.În luna iulie, oamenii de știință au zburat pentru a colecta mostre la ceea ce credeau că este insula Oodaaq, care este cunoscută din 1978. Dar când au verificat poziția lor cu oficialul danez responsabil cu înregistrarea insulelor arctice, au constatat că se aflau cu 800 m mai la nord, potrivit BBC.Insula de 60X30m este cel mai apropiat punct de uscat de Polul Nord, spun ei. Groenlanda este un vast teritoriu arctic autonom care aparține Danemarcei.\"Insula a fost descoperită în timpul unei expediții de cercetare danezo-elvețiene, pe care eu o coordonam\", a declarat pentru BBC conducătorul științific Morten Rasch, de la Stația Arctică din Groenlanda, Universitatea din Copenhaga.\"Am vrut, printre multe alte lucruri, să vizităm insula Oodaaq, care era cunoscută anterior ca fiind cea mai nordică insulă\".Din punct de vedere științific, \"nu este mare lucru\"Morten Rasch a spus că echipa sa \"a vrut să ia probe de pe insulă pentru a căuta noi specii care sunt adaptate la o viață în acest mediu foarte extrem. Eram șase persoane într-un elicopter mic, iar când am ajuns în poziția insulei Oodaaq, nu am putut să o găsim\", a spus el, adăugând că hărțile nu sunt foarte precise în acea parte a lumii.\"Așadar, am început să căutăm insula. După câteva minute foarte incitante, am aterizat pe o grămadă ciudată de noroi, depozite de morena și pietriș, înconjurată de gheață de mare din toate părțile, un loc nu foarte prietenos. După expediție și multe discuții cu specialiști în domeniu, ne-am dat seama că, din întâmplare, am descoperit de fapt cea mai nordică insulă din lume\", a adăugat Rasch.Rasch a declarat că, din punct de vedere științific, \"nu este mare lucru\". \"Dar, dintr-o perspectivă personală este, desigur, cumva amuzant să fii printre cei șase oameni care au avut vreodată pe pământ cizme noroioase în cel mai nordic punct din lume\".Oamenii de știință doresc acum ca insula să fie numită Qeqertaq Avannarleq, ceea ce înseamnă \"cea mai nordică insulă\" în limba groenlandeză. Groenlanda a ajuns de mai multe ori pe prima pagină a ziarelor în ultimii ani, președintele de atunci, Donald Trump, sugerând în 2019 că SUA ar putea cumpăra acest teritoriu.\n",
      "Generated summary: Un grup de oameni de știință afirmă că au descoperit din întâmplare ceea ce cred că este cea mai nordică insulă din lume, în largul coastelor Groenlandei. Insula de 60X30m este cel mai apropiat punct de uscat din Polul Nord, spun ei, potrivit BBC. După câteva minute foarte incitante, am aterizat pe o grămadă ciudată de noroi și depozite de morena și pietriș.\n",
      "Actual summary: ['A fost descoperită cea mai nordică insulă din lume.', 'Insula Oodaaq este cunoscută din 1978.', 'Insula se află în largul coastelor Groenlandei.']\n"
     ]
    }
   ],
   "source": [
    "text_number = 12\n",
    "test_text = dataset['test'][text_number]['paragraphs']\n",
    "summary = generate_summary_t5(test_text)\n",
    "\n",
    "print(\"Original text:\", \" \".join(test_text))\n",
    "\n",
    "print(\"Generated summary:\", summary)\n",
    "\n",
    "print(\"Actual summary:\", dataset['test'][text_number]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 12.41 GiB is allocated by PyTorch, and 5.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 22\u001b[0m\n\u001b[0;32m      7\u001b[0m validation_dataset \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m500\u001b[39m]\n\u001b[0;32m      9\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[0;32m     10\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results_t5_base\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     logging_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./logs\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     20\u001b[0m )\n\u001b[1;32m---> 22\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_dataset\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     31\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./t5_model_base\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\pythonRL\\lib\\site-packages\\transformers\\trainer.py:459\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# Bnb Quantized models doesn't support `.to` operation.\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_model_on_device\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_method\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m QuantizationMethod\u001b[38;5;241m.\u001b[39mBITS_AND_BYTES\n\u001b[0;32m    458\u001b[0m ):\n\u001b[1;32m--> 459\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_move_model_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;66;03m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[39;00m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_model_parallel:\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\pythonRL\\lib\\site-packages\\transformers\\trainer.py:693\u001b[0m, in \u001b[0;36mTrainer._move_model_to_device\u001b[1;34m(self, model, device)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_move_model_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, device):\n\u001b[1;32m--> 693\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;66;03m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mparallel_mode \u001b[38;5;241m==\u001b[39m ParallelMode\u001b[38;5;241m.\u001b[39mTPU \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtie_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\pythonRL\\lib\\site-packages\\transformers\\modeling_utils.py:2595\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2590\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[0;32m   2591\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2592\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2593\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2594\u001b[0m         )\n\u001b[1;32m-> 2595\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\pythonRL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\pythonRL\\lib\\site-packages\\torch\\nn\\modules\\module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\pythonRL\\lib\\site-packages\\torch\\nn\\modules\\module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\pythonRL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 12.41 GiB is allocated by PyTorch, and 5.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "train_dataset = dataset['train'][0:1000]\n",
    "validation_dataset = dataset['validation'][0:500]\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_t5_base\",\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    fp16=True,\n",
    "    logging_dir='./logs'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "model_path = \"./t5_model_base\"\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilingual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['title', 'summary', 'url', 'paragraphs'],\n",
      "        num_rows: 38683\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['title', 'summary', 'url', 'paragraphs'],\n",
      "        num_rows: 2036\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['title', 'summary', 'url', 'paragraphs'],\n",
      "        num_rows: 2143\n",
      "    })\n",
      "})\n",
      "{'title': 'Ion Cristoiu: Drama din amor, mai tare decât adoptarea Constituţiei.', 'summary': ['Ion Cristoiu: În anii 1923-1924, numita Anny Bally din Brăila, \"de o frumuseţe rară“, a încercat să se sinucidă din dragoste. În 8 noiembrie 1924, tot din amor, şi-a împuşcat iubitul, după care s-a împuşcat şi ea.', 'Ion Cristoiu: În tot acest timp, Adunarea Deputaţilor a votat o nouă Constituţie (în 26 noiembrie 1923), considerată \"nulă\" de către Opoziţie; Guvernul liberal Ionel Brătianu a adoptat Pachetul de legi economice, prin care se înfăptuia Programul Prin noi înşine!', 'Ion Cristoiu: Nici unul dintre aceste evenimente, rămase în Istoria Patriei, n-o interesează pe domnişoara Anny, nebună de durere c-a lăsat-o numitul Militeanu, funcţionar din Comerţ. Şi nici pe cititorii celor două mari ziare, Dimineaţa şi Universul ( despărţite de politică, dar unite de suferinţele domnişoarei Anny).'], 'url': 'https://alephnews.ro/guvern/ion-cristoiu-drama-din-amor-mai-tare-decat-adoptarea-constitutiei/', 'paragraphs': ['Scrie Dimineaţa în numărul de luni, 10 noiembrie 1924:\"IMPRESIONANTA DRAMĂ DIN BRĂILAO DOMNIŞOARĂ DESCARCĂ DOUĂ FOCURI REVOLVER ASUPRA IUBITULUI SĂU ŞI APOI SE SINUCIDE.Brăila, 8. – O impresionantă dramă s-a petrecut azi dim. la orele 11 jum. în str. Ştefan cel Mare 265.D-na Anny Bally, de o frumseţe rară, în etate de 22 ani, întreţinea de mai multă vreme relaţiuni amoroase cu tînărul Natan Militeanu, de 26 ani, de profesiune funcţionar comerţ.Din cauza geloziei, Anny îşi propuse să se răzbune pe iubitul ei, care o înşela.Azi dimineaţă pe cînd Militeanu venise la ea, Anny profită de ocazie că erau singuri şi, după o discuţie violentă, a luat un revolver «Browning», pe care-l avea într-un sertar, şi a descărcat asupra sa două focuri rănindu-l grav.Nefericitul tînăr a căzut într-un lac de sînge.Criminala, crezînd că Militeanu a murit, a îndreptat revolverul asupra ei, trăgîndu-şi un glonte în piept.Moartea i-a fost fulgerătoare.La zgomotul produs de detunătura armei, au alergat vecinii.Spectacolul era înfiorător.Camera plină de sînge iar copurile celor doi tineri întinse pe pardoseală.Autorităţile, în frunte cu procurorul d. Berbeciu şi inspectorul poliţienesc Parizescu, au sosit imediat la faţa locului şi au dispus transportarea cadavrului nefericitei Anny Bally la morgă, iar pe Militeanu la spital.Anny, a lăsat două scrisori, ceea ce dovedeşte că era decisă să comită disperatul act încă mai dinainte.O scrisoare era adresată prietenei sale Anny Schvartz, iar a două «către cei ce-mi sînt dragi şi aproape de mine».În această scrisoare, ea cere iertarea şi arată cu amănunţime cauzele cari au determinat-o să facă actul disperat.Zguduitoarea dramă a produs o profundă impresie în întregul oraş unde tineri erau bine cunoscuţi.Anny Bally era singurul sprijin al familiei sale numeroase“.Universul din 12 noiembrie 1924 consacră dramei un spaţiu mult mai larg:\"În jurul dramei amoroase din BrăilaAncheta în privinţa dramei amoroase petrecute în ziua de 8 Noembrie în localitate şi a cărei eroină este d-ra Anny Bally nu s-a terminat încă. Din informaţiile pe cari le-am cules reiese că d-ra Bally întreţinea relaţiuni de dragoste cu tînărul Nathan Militeanu încă de acum 5 ani jumătate, pe cînd locuiau amîndoi pe str. Rahovei, unde îi despărţeau doar cîteva case.Anny Bally, fată serioasă şi foarte frumoasă, prinsese o adîncă simpatie pentru tînărul Militeanu. Cu timpul această iubire devenise atît de cordială, încît tînăra aspira să aranjeze o căsnicie cu tînărul Militeanu. Acesta, văzînd că legăturile de dragoste iau un caracter serios, a căutat ca să se debaraseze de iubita lui cu timpul. Sîmburele geloziei se sădise în inima Annei. La mici intervale surveneau certuri şi scene pline de reproşuri. Într-una din zile, Militeanu, profitînd de acest fapt, mărturisi iubitei sale că se va retrage, urmînd să se logodească cu o tînără fată cu avere. Desnădăjduită că va fi părăsită, tînăra fată a căutat prin diferite mijloace să-l readucă la sentimente mai bune pe iubitul ei. Toate silinţele au rămas însă zadarnice. Acum un an, Anny a încercat să se sinucidă prin strangulare, iar acum în urmă să se otrăvească. Militeanu aflînd despre aceste încercări, a revenit lîngă iubita lui, dar pentru scurt timp, pentru ca mai tîrziu să găsească un mijloc ca să se debaraseze pentru totdeauna de ea. Totul părea un timp că s-a dat uitării. Anny mărturisea prietenelor ei că va duce o nouă viaţă, dar împrejurările au fost mai tari ca voinţa ei. Tînăra fată nu putea să dea uitării pe acela pe care-l iubise atît de mult În intervalul acesta se iveşte un tînăr pretendent la mîna Annei. Ea nu i-a dat nici un răspuns. Peste puţin timp, tînărul pleacă în America, de unde îi scrie că dacă vrea să devie fericită să-l urmeze. Fie din cauza lipsei de bani, fie că Anny nu putea uita pe Militeanu, n-a răspuns propunerilor lui.Într-o zi tînăra Anny reuşi să-şi procure un revolver.Acum cîteva zile a sosit în localitate logodnica lui Militeanu. Anny aflînd şi fiind sigură că partida este pierdută, a încercat să-şi joace ultima carte. Sîmbătă, 8 noiembrie, dimineaţă, pe la orele 8, tînărul Militeanu primeşte un bilet din partea Anei în care îi spune: «Te rog, vino imediat, am să-ţi comunic ceva foarte important, în interesul tău; te aştept Anny».Militeanu, fără să bănuiască intenţia fostei sale iubite, s-a dus la locuinţa ei din strada Ştefan cel Mare, unde a fost primit imediat. Anny a rugat pe mama ei, care tocmai în dimineaţa aceia venise de la Galaţi, să-i lase singuri, deoarece au de aranjat chestiune serioase. Rămasă singură, Anny i-a reamintit lui Militeanu că are anumite obligaţiuni faţă de dînsa şi dacă este dispus să-şi ţie angajamentul. Acesta nu numai că a refuzat, dar i-a spus Annei că legăturile dintre ei sînt terminate.Atunci Anny, nebună de durere, a scos revolverul «Browning» şi a tras asupra lui Militeanu, rănindu-l grav. Crezînd că victima a murit, cu aceiaşi armă şi-a descărcat un foc în piept, moarte fiindu-i fulgerătoare.Starea lui Nathan Militeanu, care se află la spital, continuă să fie foarte gravă. Eri s-a procedat la extragerea glonţului“.În anii 1923-1924, numita Anny Bally din Brăila, \"de o frumuseţe rară“, a încercat să se sinucidă din dragoste.În 8 noiembrie 1924, tot din amor, şi-a împuşcat iubitul, după care s-a împuşcat şi ea.În tot acest timp, Adunarea Deputaţilor a votat o nouă Constituţie (în 26 noiembrie 1923), considerată \"nulă\" de către Opoziţie; Guvernul liberal Ionel Brătianu a adoptat Pachetul de legi economice, prin care se înfăptuia Programul Prin noi înşine! ; Toate ziarele scriu despre o nouă afacere de corupţie la nivel înalt: cea a Paşapoartelor; Pe 11 mai 1924, apare un nou partid: Partidul Naţionalist al Poporului, condus de Nicolae Iorga.Despre aceste evenimente se discută pătimaş în Parlament, în cafenele, ziarele le relatează sub titluri uriaşe, plasate pe prima pagină.Nici unul dintre aceste evenimente, rămase în Istoria Patriei, n-o interesează pe domnişoara Anny, nebună de durere c-a lăsat-o numitul Militeanu, funcţionar din Comerţ.Şi nici pe cititorii celor două mari ziare, Dimineaţa şi Universul ( despărţite de politică, dar unite de suferinţele domnişoarei Anny), care cumpără pe rupte şi parcurg febril amplele articole dedicate celor \" două focuri de revolver descărcate asupra iubitului\".Şi cînd te gîndeşti că mulţi îşi bat capul şi azi cu întrebarea:De ce nu ies românii la vot?NOTĂ: Acest editorial este preluat integral de pe cristoiublog.ro.']}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"readerbench/AlephNews\")\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "print(dataset['train'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MT5ForConditionalGeneration, MT5Tokenizer\n",
    "\n",
    "model_name = 'google/mt5-small'\n",
    "tokenizer = MT5Tokenizer.from_pretrained(model_name)\n",
    "model = MT5ForConditionalGeneration.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = ' ' if text is None else str(text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
    "    # Remove email addresses\n",
    "    text = re.sub(r'\\S+@\\S+\\.\\S+', '', text)\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Normalize whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Remove boilerplate notes and specific patterns\n",
    "    text = re.sub(r'NOTĂ:.*?\\.ro\\.', '', text)\n",
    "    # Remove or substitute special characters/punctuation as needed\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Optional: Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    inputs = [\"summarize: \" + \" \".join(paragraph) for paragraph in examples['paragraphs']]\n",
    "    summaries = [\" \".join(summary) for summary in examples['summary']]\n",
    "\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding='max_length', return_tensors=\"pt\")\n",
    "    labels = tokenizer(summaries, max_length=150, truncation=True, padding='max_length', return_tensors=\"pt\")\n",
    "\n",
    "    model_inputs = {key: val.tolist() for key, val in model_inputs.items()}\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"].tolist()\n",
    "\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "!set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
    "\n",
    "# Clear CUDA cache to free up memory\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_subset = tokenized_dataset['train'].select(range(1000))\n",
    "validation_subset = tokenized_dataset['validation'].select(range(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 125/1250 [36:27<5:28:04, 17.50s/it]\n",
      "  1%|          | 10/1250 [01:29<3:12:48,  9.33s/it]\n",
      "\n",
      "                                                    \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                       \n",
      "  1%|          | 10/1250 [01:29<3:12:48,  9.33s/it]\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 25878225.6, 'learning_rate': 2e-05, 'epoch': 0.08}\n",
      "{'loss': 25878225.6, 'learning_rate': 2e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1250 [03:03<3:14:15,  9.48s/it]\n",
      "\n",
      "                                                    \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                       \n",
      "  2%|▏         | 20/1250 [03:03<3:14:15,  9.48s/it]\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2e-05, 'epoch': 0.16}\n",
      "Warning: Zero loss encountered!\n",
      "{'loss': 0.0, 'learning_rate': 2e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 30/1250 [04:36<3:08:27,  9.27s/it]\n",
      "\n",
      "                                                    \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                       \n",
      "  2%|▏         | 30/1250 [04:36<3:08:27,  9.27s/it]\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2e-05, 'epoch': 0.24}\n",
      "Warning: Zero loss encountered!\n",
      "{'loss': 0.0, 'learning_rate': 2e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 40/1250 [06:09<3:07:33,  9.30s/it]\n",
      "\n",
      "                                                    \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                       \n",
      "  3%|▎         | 40/1250 [06:09<3:07:33,  9.30s/it]\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 238.7036, 'learning_rate': 2e-05, 'epoch': 0.32}\n",
      "{'loss': 238.7036, 'learning_rate': 2e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 50/1250 [07:42<3:06:02,  9.30s/it]\n",
      "\n",
      "                                                    \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                       \n",
      "  4%|▍         | 50/1250 [07:42<3:06:02,  9.30s/it]\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 20.5324, 'learning_rate': 2e-05, 'epoch': 0.4}\n",
      "{'loss': 20.5324, 'learning_rate': 2e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 60/1250 [09:15<3:03:55,  9.27s/it]\n",
      "\n",
      "                                                    \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                       \n",
      "  5%|▍         | 60/1250 [09:15<3:03:55,  9.27s/it]\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2e-05, 'epoch': 0.48}\n",
      "Warning: Zero loss encountered!\n",
      "{'loss': 0.0, 'learning_rate': 2e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 70/1250 [10:47<3:02:48,  9.30s/it]\n",
      "\n",
      "                                                    \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                       \n",
      "  6%|▌         | 70/1250 [10:47<3:02:48,  9.30s/it]\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2e-05, 'epoch': 0.56}\n",
      "Warning: Zero loss encountered!\n",
      "{'loss': 0.0, 'learning_rate': 2e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 80/1250 [12:20<3:00:36,  9.26s/it]\n",
      "\n",
      "                                                    \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                       \n",
      "  6%|▋         | 80/1250 [12:20<3:00:36,  9.26s/it]\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2e-05, 'epoch': 0.64}\n",
      "Warning: Zero loss encountered!\n",
      "{'loss': 0.0, 'learning_rate': 2e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 90/1250 [13:53<2:59:18,  9.27s/it]\n",
      "\n",
      "                                                    \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                       \n",
      "  7%|▋         | 90/1250 [13:53<2:59:18,  9.27s/it]\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2e-05, 'epoch': 0.72}\n",
      "Warning: Zero loss encountered!\n",
      "{'loss': 0.0, 'learning_rate': 2e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 100/1250 [15:25<2:57:27,  9.26s/it]\n",
      "\n",
      "                                                    \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                       \n",
      "  8%|▊         | 100/1250 [15:25<2:57:27,  9.26s/it]\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2e-05, 'epoch': 0.8}\n",
      "Warning: Zero loss encountered!\n",
      "{'loss': 0.0, 'learning_rate': 2e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 110/1250 [16:58<2:56:05,  9.27s/it]\n",
      "\n",
      "                                                    \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                       \n",
      "  9%|▉         | 110/1250 [16:58<2:56:05,  9.27s/it]\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2e-05, 'epoch': 0.88}\n",
      "Warning: Zero loss encountered!\n",
      "{'loss': 0.0, 'learning_rate': 2e-05, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 120/1250 [18:31<2:54:41,  9.28s/it]\n",
      "\n",
      "                                                    \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                       \n",
      " 10%|▉         | 120/1250 [18:31<2:54:41,  9.28s/it]\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'learning_rate': 2e-05, 'epoch': 0.96}\n",
      "Warning: Zero loss encountered!\n",
      "{'loss': 0.0, 'learning_rate': 2e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 125/1250 [19:17<2:53:30,  9.25s/it]"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 3.78 GiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 7.33 GiB is allocated by PyTorch, and 1.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 41\u001b[0m\n\u001b[0;32m     30\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[0;32m     31\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     32\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[LossDebugCallback()]\n\u001b[0;32m     38\u001b[0m )\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Save the model and tokenizer\u001b[39;00m\n\u001b[0;32m     44\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./mt5_model_small_better\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\pythonRL\\lib\\site-packages\\transformers\\trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1537\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\pythonRL\\lib\\site-packages\\transformers\\trainer.py:1944\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1941\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m-> 1944\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[0;32m   1947\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_tpu_available():\n\u001b[0;32m   1948\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\pythonRL\\lib\\site-packages\\transformers\\trainer.py:2291\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2289\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[1;32m-> 2291\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[0;32m   2294\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\pythonRL\\lib\\site-packages\\transformers\\trainer_seq2seq.py:166\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gen_kwargs \u001b[38;5;241m=\u001b[39m gen_kwargs\n\u001b[1;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\pythonRL\\lib\\site-packages\\transformers\\trainer.py:3095\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3092\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   3094\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 3095\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3096\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3098\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[0;32m   3099\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[0;32m   3100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3103\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3105\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[0;32m   3106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\pythonRL\\lib\\site-packages\\transformers\\trainer.py:3310\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3308\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_logits_for_metrics(logits, labels)\n\u001b[0;32m   3309\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function((logits))\n\u001b[1;32m-> 3310\u001b[0m     preds_host \u001b[38;5;241m=\u001b[39m logits \u001b[38;5;28;01mif\u001b[39;00m preds_host \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3313\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function((labels))\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\pythonRL\\lib\\site-packages\\transformers\\trainer_pt_utils.py:121\u001b[0m, in \u001b[0;36mnested_concat\u001b[1;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtype\u001b[39m(\n\u001b[0;32m    118\u001b[0m     new_tensors\n\u001b[0;32m    119\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected `tensors` and `new_tensors` to have the same type but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(new_tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_tensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_pad_and_concatenate(tensors, new_tensors, padding_index\u001b[38;5;241m=\u001b[39mpadding_index)\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\pythonRL\\lib\\site-packages\\transformers\\trainer_pt_utils.py:121\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtype\u001b[39m(\n\u001b[0;32m    118\u001b[0m     new_tensors\n\u001b[0;32m    119\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected `tensors` and `new_tensors` to have the same type but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(new_tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(\u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tensors, new_tensors))\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_pad_and_concatenate(tensors, new_tensors, padding_index\u001b[38;5;241m=\u001b[39mpadding_index)\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\pythonRL\\lib\\site-packages\\transformers\\trainer_pt_utils.py:123\u001b[0m, in \u001b[0;36mnested_concat\u001b[1;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(nested_concat(t, n, padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m t, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tensors, new_tensors))\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_pad_and_concatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, Mapping):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(\n\u001b[0;32m    126\u001b[0m         {k: nested_concat(t, new_tensors[k], padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensors\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    127\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\RoG\\anaconda3\\envs\\pythonRL\\lib\\site-packages\\transformers\\trainer_pt_utils.py:82\u001b[0m, in \u001b[0;36mtorch_pad_and_concatenate\u001b[1;34m(tensor1, tensor2, padding_index)\u001b[0m\n\u001b[0;32m     79\u001b[0m tensor2 \u001b[38;5;241m=\u001b[39m atleast_1d(tensor2)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensor1\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m---> 82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Let's figure out the new shape\u001b[39;00m\n\u001b[0;32m     85\u001b[0m new_shape \u001b[38;5;241m=\u001b[39m (tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mmax\u001b[39m(tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m+\u001b[39m tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:]\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.78 GiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 7.33 GiB is allocated by PyTorch, and 1.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, TrainerCallback\n",
    "\n",
    "\n",
    "\n",
    "# Training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./resultsMT5_better',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,  # Further reduce if possible, depending on your model architecture\n",
    "    gradient_accumulation_steps=8,  # Increase if reducing batch size to maintain effective batch size\n",
    "    per_device_eval_batch_size=1,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=10,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    fp16=True,  # Ensure that mixed precision is enabled\n",
    "\n",
    ")\n",
    "\n",
    "# Custom callback to monitor the loss\n",
    "class LossDebugCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        print(logs)\n",
    "        if 'loss' in logs and logs['loss'] == 0:\n",
    "            print(\"Warning: Zero loss encountered!\")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=training_subset,\n",
    "    eval_dataset=validation_subset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=lambda eval_pred: {\"loss\": eval_pred.loss},\n",
    "    callbacks=[LossDebugCallback()]\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save the model and tokenizer\n",
    "model_path = \"./mt5_model_small_better\"\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test_data(text):\n",
    "    # Join the list of paragraphs into a single string if text is a list\n",
    "    if isinstance(text, list):\n",
    "        text = \" \".join(text)\n",
    "    print(\"Preprocessed text:\", text)  # Debug: Print to verify the processed text\n",
    "    inputs = tokenizer(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True, padding='max_length')\n",
    "    inputs = {key: val.to(model.device) for key, val in inputs.items()}\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def generate_summary(test_data):\n",
    "    model.eval()  # Set the model to eval mode\n",
    "    with torch.no_grad():  # Disable gradient calculation for inference\n",
    "        # Extract 'input_ids' and 'attention_mask', ensuring they are tensors and adding a batch dimension\n",
    "        input_ids = torch.tensor(test_data['input_ids']).unsqueeze(0).to(model.device)\n",
    "        attention_mask = torch.tensor(test_data['attention_mask']).unsqueeze(0).to(model.device)\n",
    "        \n",
    "        # Generate outputs using the model\n",
    "        outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=150, num_beams=5, early_stopping=True)\n",
    "        \n",
    "        # Decode generated token IDs to a string summary\n",
    "        summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: {'title': '\"Boema\" lui Puccini, pe timp de pandemie. Primul spectacol de operă live drive-in din Europa.', 'summary': ['Pandemia a dus anul ăsta la o premieră în lumea spectacolelor: opera drive-in.', '\"Boema\" lui Puccini s-a jucat pentru prima dată într-o parcare şi a fost urmărită din maşini.', 'Opera de la Bucureşti şi-a redeschis porţile şi te aşteaptă la spectacole.'], 'url': 'https://alephnews.ro/entertainment/boema-lui-puccini-pe-timp-de-pandemie-primul-spectacol-de-opera-live-drive-in-din-europa/', 'paragraphs': ['Englezilor le place să facă lucrurile altfel. Și încearcă să nu te dezamăgească niciodată. Primul spectacol de operă live drive-in din Europa a avut loc în weekend la Londra.S-a jucat \"Boema\" lui Puccini, în parcarea de la Alexandra Palace.Sala de evenimente, faimoasă în oraş, e închisă încă de la începutul pandemiei.Așa că spectacolul a fost adaptat vremurilor. Spectatorii au stat în mașini și au fost serviţi cu îngheţată, ciocolată şi băuturi.Şi-au reglat radiourile pe aceeaşi frecvenţă, ca să asculte operaAlții au preferat să stea cu geamurile deschise şi să audă direct de pe scenă.La final, în loc de aplauze, artiștii au primit claxoane. Tot în semn de admirație…Opera de la Bucureşti te aşteaptă şi ea din nou la spectacole începând din weekendul ăsta, după mai bine de şase luni de pauză.Doar 130 din cele 915 bilete vor fi scoase la vânzare, pentru a respecta normele impuse de autorităţi.'], 'input_ids': [196098, 10701, 267, 642, 110323, 4820, 340, 2554, 1464, 899, 4560, 11021, 6635, 440, 107740, 260, 20145, 266, 38608, 372, 4560, 1464, 703, 400, 269, 32771, 782, 318, 28389, 259, 52277, 26381, 260, 26916, 454, 101485, 4708, 269, 21685, 782, 4657, 12317, 264, 348, 779, 5403, 259, 262, 259, 18077, 8811, 732, 15699, 283, 63437, 262, 260, 399, 264, 262, 1218, 2162, 313, 22484, 15790, 311, 3460, 4852, 202996, 261, 732, 624, 96881, 269, 283, 259, 77243, 28073, 260, 133630, 269, 259, 37531, 265, 261, 8406, 282, 85129, 732, 8065, 1907, 261, 259, 265, 63317, 14748, 259, 40258, 269, 283, 732, 27676, 454, 47842, 265, 266, 260, 357, 44815, 2003, 101485, 179053, 259, 262, 3432, 65105, 270, 118144, 16744, 260, 55559, 270, 80094, 804, 9853, 732, 496, 1148, 516, 259, 1148, 804, 3432, 19844, 5250, 651, 732, 34844, 15521, 4394, 261, 2708, 234959, 782, 1550, 34818, 176503, 260, 8966, 266, 264, 1340, 74406, 270, 7534, 6635, 603, 259, 42343, 59071, 92770, 857, 47171, 261, 960, 1464, 259, 130045, 265, 7248, 7759, 9311, 804, 14310, 523, 1464, 122663, 651, 684, 579, 6635, 40814, 569, 1550, 1464, 804, 30558, 3867, 269, 603, 44516, 782, 260, 2470, 2733, 261, 732, 8811, 269, 149534, 1043, 261, 31162, 88035, 804, 59817, 317, 111086, 73552, 260, 18454, 732, 71792, 269, 102350, 10479, 302, 80351, 269, 283, 57808, 18792, 400, 259, 94404, 262, 45630, 1550, 259, 265, 262, 779, 4183, 283, 177485, 4505, 38608, 325, 10515, 779, 15699, 454, 259, 782, 1208, 261, 413, 6735, 784, 12224, 269, 78747, 569, 259, 25353, 269, 19480, 25453, 260, 12671, 372, 9281, 779, 7654, 149192, 30012, 265, 1497, 1090, 36054, 8339, 283, 259, 52637, 20186, 261, 259, 1175, 259, 262, 7521, 262, 15651, 1094, 88034, 569, 269, 4796, 92796, 260, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [103290, 25796, 259, 262, 16827, 24403, 259, 782, 1208, 283, 259, 268, 8876, 782, 732, 18891, 262, 177485, 77699, 286, 267, 7248, 12317, 264, 348, 260, 313, 22484, 15790, 311, 3460, 4852, 202996, 259, 263, 264, 262, 1218, 2162, 259, 1175, 5237, 259, 26381, 16442, 264, 268, 624, 6845, 1550, 259, 262, 3432, 39680, 179795, 779, 496, 206404, 260, 14411, 269, 283, 57808, 18792, 1550, 264, 262, 14114, 2535, 263, 519, 5250, 468, 1550, 400, 259, 94404, 262, 45630, 283, 177485, 4505, 260, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "test_text = tokenized_dataset['test'][0]\n",
    "\n",
    "print(\"Original text:\", test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_summary\u001b[49m(test_text)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated summary:\u001b[39m\u001b[38;5;124m\"\u001b[39m, summary)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generate_summary' is not defined"
     ]
    }
   ],
   "source": [
    "summary = generate_summary(test_text)\n",
    "\n",
    "print(\"Generated summary:\", summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "licenta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
