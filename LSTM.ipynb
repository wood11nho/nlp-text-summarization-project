{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Instalăm pachetele necesare\n!pip install numpy pandas keras tensorflow datasets nltk beautifulsoup4\n\nimport numpy as np\nimport pandas as pd\nimport re\nfrom bs4 import BeautifulSoup\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom nltk.corpus import stopwords\nimport nltk\nfrom tensorflow.keras.layers import Input, LSTM, Embedding, Dense, TimeDistributed, Bidirectional, Concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport warnings","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setări inițiale\npd.set_option(\"display.max_colwidth\", 200)\nwarnings.filterwarnings(\"ignore\")\nnltk.download('stopwords')\nstopwords = set(stopwords.words('romanian'))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Încărcăm dataset-ul\nfrom datasets import load_dataset\ndataset = load_dataset(\"readerbench/ro-text-summarization\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Funcții pentru curățarea textelor în limba română\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r'\\([^)]*\\)', '', text)\n    text = re.sub('\"', '', text)\n    text = re.sub(r\"\\'s\\b\", \"\", text)\n    text = re.sub(\"[^a-zăîâșț]\", \" \", text)\n    tokens = [w for w in text.split() if not w in stopwords]\n    long_words = [i for i in tokens if len(i) >= 3]\n    return \" \".join(long_words).strip()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_summary(text):\n    text = text.lower()\n    text = re.sub('\"', '', text)\n    text = re.sub(r\"\\'s\\b\", \"\", text)\n    text = re.sub(\"[^a-zăîâșț]\", \" \", text)\n    tokens = [w for w in text.split() if len(w) > 1]\n    return \"start \" + \" \".join(tokens) + \" end\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Curățăm și tokenizăm datele\ntrain_texts = [clean_text(t) for t in dataset['train']['Content']]\ntrain_summaries = [clean_summary(t) for t in dataset['train']['Summary']]\ntest_texts = [clean_text(t) for t in dataset['test']['Content']]\ntest_summaries = [clean_summary(t) for t in dataset['test']['Summary']]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenizare și padare\nmax_text_len = 100\nmax_summary_len = 20","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenizăm textele\nx_tokenizer = Tokenizer(num_words=30000)\nx_tokenizer.fit_on_texts(train_texts)\ntrain_texts_seq = x_tokenizer.texts_to_sequences(train_texts)\ntest_texts_seq = x_tokenizer.texts_to_sequences(test_texts)\n\ntrain_texts_pad = pad_sequences(train_texts_seq, maxlen=max_text_len, padding='post')\ntest_texts_pad = pad_sequences(test_texts_seq, maxlen=max_text_len, padding='post')\nx_voc_size = len(x_tokenizer.word_index) + 1","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenizăm rezumatele\ny_tokenizer = Tokenizer(num_words=8000)\ny_tokenizer.fit_on_texts(train_summaries)\ntrain_summaries_seq = y_tokenizer.texts_to_sequences(train_summaries)\ntest_summaries_seq = y_tokenizer.texts_to_sequences(test_summaries)\n\ntrain_summaries_pad = pad_sequences(train_summaries_seq, maxlen=max_summary_len, padding='post')\ntest_summaries_pad = pad_sequences(test_summaries_seq, maxlen=max_summary_len, padding='post')\ny_voc_size = len(y_tokenizer.word_index) + 1","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Curățarea sesiunii Keras\nfrom keras import backend as K\nK.clear_session()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dimensiunea latenților și definirea modelului\nlatent_dim = 256\n\n# Encoder\nencoder_inputs = Input(shape=(max_text_len,))\nenc_emb = Embedding(x_voc_size, latent_dim, trainable=True)(encoder_inputs)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LSTM Bidirecțional în encoder\nencoder_lstm = Bidirectional(LSTM(latent_dim, return_sequences=True, return_state=True))\nencoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_lstm(enc_emb)\n\nstate_h = Concatenate()([forward_h, backward_h])\nstate_c = Concatenate()([forward_c, backward_c])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Decoder\ndecoder_inputs = Input(shape=(None,))\ndec_emb_layer = Embedding(y_voc_size, latent_dim * 2, trainable=True)\ndec_emb = dec_emb_layer(decoder_inputs)\n\ndecoder_lstm = LSTM(latent_dim * 2, return_sequences=True, return_state=True)\ndecoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n\ndecoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax'))\ndecoder_outputs = decoder_dense(decoder_outputs)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Modelul complet\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compilarea modelului\nmodel.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\nmodel.summary()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Antrenarea modelului\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\nhistory = model.fit([train_texts_pad, train_summaries_pad[:,:-1]],\n                    train_summaries_pad.reshape(train_summaries_pad.shape[0], train_summaries_pad.shape[1], 1)[:,1:],\n                    epochs=50, callbacks=[es], batch_size=64,\n                    validation_data=([test_texts_pad, test_summaries_pad[:,:-1]],\n                                     test_summaries_pad.reshape(test_summaries_pad.shape[0], test_summaries_pad.shape[1], 1)[:,1:]))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Vizualizarea pierderii în timp\nfrom matplotlib import pyplot as plt\nplt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='test')\nplt.legend()\nplt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pregătirea pentru decodare\nreverse_target_word_index = y_tokenizer.index_word\nreverse_source_word_index = x_tokenizer.index_word\ntarget_word_index = y_tokenizer.word_index\n\nencoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n\ndecoder_state_input_h = Input(shape=(latent_dim * 2,))\ndecoder_state_input_c = Input(shape=(latent_dim * 2,))\ndecoder_hidden_state_input = Input(shape=(max_text_len, latent_dim * 2))\n\ndec_emb2 = dec_emb_layer(decoder_inputs)\n\ndecoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\ndecoder_outputs2 = decoder_dense(decoder_outputs2)\n\ndecoder_model = Model(\n    [decoder_inputs] + [decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],\n    [decoder_outputs2] + [state_h2, state_c2])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Funcția pentru decodarea secvenței\ndef decode_sequence(input_seq):\n    e_out, e_h, e_c = encoder_model.predict(input_seq)\n    target_seq = np.zeros((1, 1))\n    target_seq[0, 0] = target_word_index['start']\n    stop_condition = False\n    decoded_sentence = ''\n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_token = reverse_target_word_index.get(sampled_token_index, '')\n        if sampled_token != 'end':\n            decoded_sentence += ' ' + sampled_token\n        if sampled_token == 'end' or len(decoded_sentence.split()) >= max_summary_len - 1:\n            stop_condition = True\n        target_seq = np.zeros((1, 1))\n        target_seq[0, 0] = sampled_token_index\n        e_h, e_c = h, c\n    return decoded_sentence.strip()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Funcțiile pentru conversie text-sum și invers\ndef seq2summary(input_seq):\n    new_string = ''\n    for i in input_seq:\n        if (i != 0 and i != target_word_index['start'] and i != target_word_index['end']):\n            new_string += reverse_target_word_index.get(i, '') + ' '\n    return new_string.strip()\n\ndef seq2text(input_seq):\n    new_string = ''\n    for i in input_seq:\n        if i != 0:\n            new_string += reverse_source_word_index.get(i, '') + ' '\n    return new_string.strip()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testarea rezumatului pe câteva exemple\nfor i in range(5):\n    print(\"Text:\", seq2text(train_texts_pad[i]))\n    print(\"Rezumat Original:\", seq2summary(train_summaries_pad[i]))\n    print(\"Rezumat Prezis:\", decode_sequence(train_texts_pad[i].reshape(1, max_text_len)))\n    print(\"\\n\\n\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]}]}